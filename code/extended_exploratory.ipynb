{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-exploratory Analysis\n",
    "\n",
    "As the start of our second pass through the epicycle, we wish to refine and expand our exploratory analysis. We will compute vertex and edge features on our graphs across multiple scales and multiple datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from subprocess import Popen, PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets: ../data/MRN114, ../data/KKI2009, ../data/SWU4\n",
      "D = 3\n"
     ]
    }
   ],
   "source": [
    "# Initializing dataset names\n",
    "dnames = list(['../data/MRN114', '../data/KKI2009', '../data/SWU4'])\n",
    "print \"Datasets: \" + \", \".join(dnames)\n",
    "print \"D = \" + str(len(dnames))\n",
    "\n",
    "# Getting graph names\n",
    "fs = dict()\n",
    "for dd in dnames:\n",
    "        fs[dd] = [root+'/'+fl for root, dir, files in os.walk(dd) for fl in files if fl.endswith(\".graphml\")]\n",
    "# fs[dnames[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadGraphs(filenames, printer=False):\n",
    "    gstruct = {}\n",
    "    for idx, files in enumerate(filenames):\n",
    "        if printer:\n",
    "            print \"Loading: \" + files\n",
    "        gstruct[files] = nx.read_graphml(files)\n",
    "    return gstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mygs = loadGraphs(fs[fs.keys()[2]], printer=False) # only loads graphs for kki dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Non-Zero (NNZ) edge weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnz = {key: len(nx.edges(mygs[key])) for key in mygs}\n",
    "# nnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vertex Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "degrees = {key: np.array(nx.degree(mygs[key]).values()) for key in mygs}\n",
    "avg_degrees = [np.mean(degrees[key]) for key in degrees]\n",
    "# avg_degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e_weights = {key: [mygs[key].get_edge_data(e[0],e[1])['weight']\n",
    "             for e in mygs[key].edges()] for key in mygs}\n",
    "avg_e_weights = [{'N': len(e_weights[key]),\n",
    "                  'mean':np.mean(e_weights[key]),\n",
    "                  'std':np.std(e_weights[key])} for key in e_weights]\n",
    "# avg_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e_count = {key: len(e_weights[key]) for key in e_weights}\n",
    "# e_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Local 3-cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "three_cliques = {key: [clique for clique in\n",
    "                       nx.algorithms.clique.enumerate_all_cliques(mygs[key])\n",
    "                       if len(clique) == 3] for key in mygs}\n",
    "n_three_cliques = [len(three_cliques[key]) for key in three_cliques]\n",
    "# n_three_cliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccoefs = {key: nx.clustering(mygs[key]).values() for key in mygs}\n",
    "avg_ccoefs = [np.mean(ccoefs[key]) for key  in ccoefs]\n",
    "# avg_ccoefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scan Statistic-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "def scan_statistic(mygs, i):\n",
    "    ss = dict()\n",
    "    for key in mygs.keys():\n",
    "        g = mygs[key]\n",
    "        tmp = np.array(())\n",
    "        for n in g.nodes():\n",
    "            subgraph = nx.ego_graph(g, n, radius = i)\n",
    "            tmp = np.append(tmp, np.sum([subgraph.get_edge_data(e[0],e[1])['weight'] for e in subgraph.edges()]))\n",
    "        ss[key] = tmp\n",
    "    return ss\n",
    "\n",
    "ss1 = scan_statistic(mygs, i)\n",
    "# ss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "ss2 = scan_statistic(mygs, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigen value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "laplacian = {key: nx.normalized_laplacian_matrix(mygs[key]) for key in mygs}\n",
    "eigs = {key: np.linalg.eigvals(laplacian[key].A) for key in laplacian}\n",
    "# eigs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centrality = {key: nx.algorithms.betweenness_centrality(mygs[key]).values() for key in mygs.keys()}\n",
    "# centrality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connected Compontent (abandonning for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ccs = {keys: nx.connected_component_subgraphs(mygs[keys]) for keys in mygs.keys()}\n",
    "# nccs = {keys: len(list(ccs[keys])) for keys in ccs.keys()}\n",
    "# print nccs\n",
    "lccs = {keys: max(ccs[keys], key=len) for keys in ccs.keys()}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
